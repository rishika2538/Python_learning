{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishika2538/Python_learning/blob/main/Day3_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## problem 1\n",
        "Create a dictionary where the keys correspond to the area of a flat adn value for each is the price of the house for 10 flat in kompally"
      ],
      "metadata": {
        "id": "B1Fhdmi9V3LI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary of house area and house prices of 10 houses in\n",
        "#HInt: area_price = {area:price}\n",
        "flat_prices = {1200:89.0,1000:78.0,1500:120.0,1400:110.0,900:69.0,500:40.0,100:23.0,800:58.0,1600:145.0,7000:580.0}\n",
        "print(flat_prices)"
      ],
      "metadata": {
        "id": "zihWmw3NWXQX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3051c8e0-b98a-44bd-b304-d868ca0fbcf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1200: 89.0, 1000: 78.0, 1500: 120.0, 1400: 110.0, 900: 69.0, 500: 40.0, 100: 23.0, 800: 58.0, 1600: 145.0, 7000: 580.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now broker predicts the price as can be written as : <b><code>predicted_price(area) = 0.06*area + 15</code></b>"
      ],
      "metadata": {
        "id": "JI2jaDf8Wp2D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the concept of list comprehension,create a list of predicted flat price using the above formula\n"
      ],
      "metadata": {
        "id": "v_K_Z8dtW6-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_predicted_prices(areas):\n",
        "    return [0.06 * area + 15 for area in areas]\n",
        "predicted_prices = calculate_predicted_prices(flat_prices.keys())\n",
        "print(predicted_prices)"
      ],
      "metadata": {
        "id": "F732P6DHXVYH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33f89f60-594c-42b2-f1f7-4066302a7d46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[87.0, 75.0, 105.0, 99.0, 69.0, 45.0, 21.0, 63.0, 111.0, 435.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create another list which contains the squares of differences of each element of the two price lists : the actual prices and the predicted prices\n"
      ],
      "metadata": {
        "id": "-ZrRO78DXZq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "squared_differences = [(actual_price - predicted_price) ** 2 for actual_price, predicted_price in zip(flat_prices.values(), predicted_prices)]\n",
        "\n",
        "print(squared_differences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNvwmxCRAIHO",
        "outputId": "7f1109c3-7e90-4183-a426-f52534db6dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4.0, 9.0, 225.0, 121.0, 0.0, 25.0, 4.0, 25.0, 1156.0, 21025.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <u> Problem 2</u>\n",
        "\n",
        "## A sigmoid function is a mathematical function having a characteristic \"S\"-shaped curve or sigmoid curve. A common example of a sigmoid function is the logistic function shown in the first figure and defined by the formula:\n",
        "\n",
        "$$ h(x) =  \\frac{\\mathrm{1} }{\\mathrm{1} + e^{-x} }  $$\n",
        "\n",
        "\n",
        "## Range is defined as all the possible values which the function $h(x)$ can take. Domain is defined as all the possible values which $x$ can take. In this case, range of the function is between 0 to 1 and the domain of the function is all real numbers"
      ],
      "metadata": {
        "id": "PEC_OtXRXrCg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### You are given a list of values of $x$. You need to use list comprehension to calculate the corresponding transformation according to the sigmoid function defined above"
      ],
      "metadata": {
        "id": "YZCTres_XsB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Return a list of boolean values if the sigmoid_of_x is greater than or equal to 0 and less than or equal to 1\n",
        "import math\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + math.exp(-x))\n",
        "x_values = [0, 1, 2, 3, 4, 5]\n",
        "sigmoid_transform = [sigmoid(x) for x in x_values]\n",
        "boolean_values = [0 <= value <= 1 for value in sigmoid_transform]\n",
        "print(boolean_values)\n",
        "\n",
        "# Create a list of those values which are greater than 0.5\n",
        "values= [value for value in sigmoid_transform if value > 0.5]\n",
        "print(values)"
      ],
      "metadata": {
        "id": "TmYb4SluYC4S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "194cd4c9-8c63-4775-acbb-6d18bdb71fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[True, True, True, True, True, True]\n",
            "[0.7310585786300049, 0.8807970779778823, 0.9525741268224334, 0.9820137900379085, 0.9933071490757153]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <u> Problem 3</u>\n",
        "\n",
        "## You are given a sentence : <code>\"I have been walking and running and dancing and smiling and laughing all my life, yet it all seems pointless. So i stoped thinking and started doing\"</code>\n",
        "\n",
        "## You are required to extract all those words from this sentence in a list which ends with <code>ing</code>"
      ],
      "metadata": {
        "id": "j31JnVUtYNU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your sentence\n",
        "my_sentence = \"I have been walking and running and dancing and smiling and laughing all my life, yet it all seems pointless.\"\n",
        "\n",
        "# Extract words ending with 'ing' using list comprehension\n",
        "words=my_sentence.split()\n",
        "result=[]\n",
        "for word in words:\n",
        "  if word.endswith('ing'):\n",
        "    word=word.strip(\",.\")\n",
        "    result.append(word)\n",
        "\n",
        "# Print the resulting list\n",
        "print(result)"
      ],
      "metadata": {
        "id": "8s6rFnH2YO1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3d94759-293a-48c2-e931-eaf2339a842a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['walking', 'running', 'dancing', 'smiling', 'laughing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <u> Problem 4</u>\n",
        "\n",
        "#### Natural Language Processing or NLP is one of the most promising fields in Machine Learning. Most of the times in NLP we deal with the textual data (a bunch of strings). Sometimes when we are processing the text, it is a common practice to get rid of some set of stop words from our original text. By default stop words are very common words used in English language such as and, or, punctuations etc.\n",
        "\n",
        "#### In this exercise, you are provided with a default set of stop words and you need to add some extra set of custom words and remove these words from the given sentence and obtain the sentence without the stop words"
      ],
      "metadata": {
        "id": "rYwInhGlYOyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A sample sentence\n",
        "sample_sentence = \"Natural Language Processing or NLP is one of the most promising fields in Machine Learning. Most of the times in NLP we deal with the textual data (a bunch of strings). Sometimes when we are processing the text, it is a common practice to get rid of some set of stop words from our original text. By default stop words are very common words used in English language such as and, or, punctuations etc.\"\n",
        "# Print your sentence\n",
        "print(sample_sentence)"
      ],
      "metadata": {
        "id": "b86yHqHEYOpp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "064bed79-118d-4d1a-fa26-a2d92fb4b533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural Language Processing or NLP is one of the most promising fields in Machine Learning. Most of the times in NLP we deal with the textual data (a bunch of strings). Sometimes when we are processing the text, it is a common practice to get rid of some set of stop words from our original text. By default stop words are very common words used in English language such as and, or, punctuations etc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Default set of stop words\n",
        "stop_words = {\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\",\n",
        "              \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\",\n",
        "              \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\",\n",
        "              \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\",\n",
        "              \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\",\n",
        "              \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\",\n",
        "              \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\",\n",
        "              \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\",\n",
        "              \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\",\n",
        "              \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\",\n",
        "              \"don\", \"should\", \"now\"}"
      ],
      "metadata": {
        "id": "RbyJscXWYh0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "custom_stop_words = [\"hello\",\"folks\",\"good\",\"morning\",\"half\",\"year\"]\n",
        "# Update the set of stop words by adding the custom stop words\n",
        "stop_words.update(custom_stop_words)\n",
        "\n",
        "# Print the updated set of stop words\n",
        "print(stop_words)"
      ],
      "metadata": {
        "id": "JCZ3mWDEYplT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24ab97ec-4c83-4642-fdca-18fda7c07954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'an', 'after', 'both', 't', 'have', 'because', 'its', 'theirs', 'above', 'does', 'more', 'about', 'were', 'these', 'all', 'but', 'don', 'me', 'half', 'him', 'was', 'same', 'those', 'over', 'now', 'herself', 'what', 'so', 'only', 'very', 'myself', 'been', 'hello', 'any', 'down', 'off', 'this', 'with', 'which', 'up', 'below', 'until', 'ourselves', 'where', 'themselves', 'itself', 'having', 'from', 'too', 'doing', 'can', 'the', 'nor', 'his', 'they', 'ours', 'than', 'into', 'some', 'be', 'our', 'good', 'your', 'who', 'you', 'of', 'such', 'am', 'that', 'yours', 'other', 'out', 'are', 'do', 'i', 'will', 'own', 'we', 'on', 'during', 'year', 'for', 'against', 'has', 'yourself', 'no', 'not', 'himself', 'had', 'them', 'whom', 'she', 'just', 'a', 's', 'each', 'to', 'under', 'should', 'before', 'then', 'once', 'my', 'it', 'between', 'how', 'hers', 'most', 'is', 'her', 'their', 'in', 'why', 'there', 'did', 'through', 'or', 'when', 'and', 'at', 'he', 'here', 'few', 'further', 'being', 'again', 'folks', 'if', 'while', 'morning', 'yourselves', 'as', 'by'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the list of words in the given sentence.\n",
        "words_in_sentence = sample_sentence.split()\n",
        "\n",
        "# Print the list of words\n",
        "print(words_in_sentence)"
      ],
      "metadata": {
        "id": "OG_iCUm9Yyx3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d780a857-e486-4f8f-efb4-947aca97ff28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural', 'Language', 'Processing', 'or', 'NLP', 'is', 'one', 'of', 'the', 'most', 'promising', 'fields', 'in', 'Machine', 'Learning.', 'Most', 'of', 'the', 'times', 'in', 'NLP', 'we', 'deal', 'with', 'the', 'textual', 'data', '(a', 'bunch', 'of', 'strings).', 'Sometimes', 'when', 'we', 'are', 'processing', 'the', 'text,', 'it', 'is', 'a', 'common', 'practice', 'to', 'get', 'rid', 'of', 'some', 'set', 'of', 'stop', 'words', 'from', 'our', 'original', 'text.', 'By', 'default', 'stop', 'words', 'are', 'very', 'common', 'words', 'used', 'in', 'English', 'language', 'such', 'as', 'and,', 'or,', 'punctuations', 'etc.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use list comprehension to remove the set of updated stop words from the list of words\n",
        "filtered_words = [word for word in words_in_sentence if word.lower() not in stop_words]\n",
        "\n",
        "# Print the filtered list of words\n",
        "print(filtered_words)"
      ],
      "metadata": {
        "id": "Kk665UtXY3UH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e49ac09-f1d1-481e-ed25-bea23b2f2756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural', 'Language', 'Processing', 'NLP', 'one', 'promising', 'fields', 'Machine', 'Learning.', 'times', 'NLP', 'deal', 'textual', 'data', '(a', 'bunch', 'strings).', 'Sometimes', 'processing', 'text,', 'common', 'practice', 'get', 'rid', 'set', 'stop', 'words', 'original', 'text.', 'default', 'stop', 'words', 'common', 'words', 'used', 'English', 'language', 'and,', 'or,', 'punctuations', 'etc.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally using the join() method, get the sentence without the stop words. Keep in mind that every word in the sentence will be separated by space\n",
        "sentence_without_stop_words = ' '.join(filtered_words)\n",
        "\n",
        "# # Print the modified sentence\n",
        "print(sentence_without_stop_words)"
      ],
      "metadata": {
        "id": "RzO-jDZVY6wD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50d67c47-e564-4905-8d29-f417b84a1361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural Language Processing NLP one promising fields Machine Learning. times NLP deal textual data (a bunch strings). Sometimes processing text, common practice get rid set stop words original text. default stop words common words used English language and, or, punctuations etc.\n"
          ]
        }
      ]
    }
  ]
}